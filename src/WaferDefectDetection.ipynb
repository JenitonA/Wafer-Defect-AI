{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wafer Defect Detection\n",
    "\n",
    "This notebook walks through the process of building and training a model to detect defects on semiconductor wafers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "Import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage import measure\n",
    "from skimage.transform import radon\n",
    "from skimage.transform import probabilistic_hough_line\n",
    "from scipy import interpolate\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "\n",
    "Here we define the Convolutional Neural Network (CNN) architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Builds a convolutional neural network (CNN) for image classification.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): The shape of the input images (height, width, channels).\n",
    "        num_classes (int): The number of classes for classification.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: The compiled CNN model.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build and Summarize Model\n",
    "\n",
    "Now, let's instantiate the model with our specific parameters and print its summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset parameters\n",
    "INPUT_SHAPE = (128, 128, 1)  # Example: 128x128 grayscale images\n",
    "NUM_CLASSES = 9  # Example: 8 defect types + 1 normal\n",
    "\n",
    "# Build the model\n",
    "model = build_model(INPUT_SHAPE, NUM_CLASSES)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data\n",
    "\n",
    "Load the wafer map data from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notebook is in the 'src' directory, so we go up one level to find the 'data' directory.\n",
    "file_path = os.path.join('..', 'data', 'LSWMD.pkl')\n",
    "df = pd.read_pickle(file_path)\n",
    "\n",
    "# Display the first few rows to verify it loaded correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing and Cleaning\n",
    "\n",
    "Prepare the data for the model. This includes dropping unnecessary columns and converting labels into a numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'waferIndex' is not needed for classification\n",
    "df = df.drop(['waferIndex'], axis = 1)\n",
    "\n",
    "# Create new columns with numerical representations of the labels\n",
    "df['failureNum'] = df.failureType\n",
    "df['trainTestNum'] = df.trianTestLabel\n",
    "mapping_type = {'Center':0, 'Donut':1, 'Edge-Loc':2, 'Edge-Ring':3, 'Loc':4, 'Random':5, 'Scratch':6, 'Near-full':7, 'none':8}\n",
    "mapping_traintest = {'Training':0, 'Test':1}\n",
    "df = df.replace({'failureNum': mapping_type, 'trainTestNum': mapping_traintest})\n",
    "\n",
    "# Check the data types and non-null counts\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Exploration and Visualization\n",
    "\n",
    "Let's visualize some of the wafer maps to get a feel for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for wafers that have a defect pattern (i.e., are not 'none')\n",
    "df_withpattern = df[(df['failureNum'] >= 0) & (df['failureNum'] <= 7)]\n",
    "df_withpattern = df_withpattern.reset_index()\n",
    "\n",
    "# Display the first 20 defect patterns\n",
    "num_to_show = 20\n",
    "fig, ax = plt.subplots(nrows=2, ncols=10, figsize=(20, 5))\n",
    "ax = ax.ravel(order='C')\n",
    "for i in range(num_to_show):\n",
    "    img = df_withpattern.waferMap[i]\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(df_withpattern.failureType[i][0][0], fontsize=10)\n",
    "    ax[i].set_xlabel(df_withpattern.index[i], fontsize=8)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps (TODO)\n",
    "\n",
    "Now that the data is loaded and preprocessed, the next steps are:\n",
    "\n",
    "- **Preprocess the images**: Resize, normalize, etc.\n",
    "- **Split the data**: Divide the data into training and testing sets using the `trainTestNum` column.\n",
    "- **Train the model**: Use `model.fit()` with the training data.\n",
    "- **Evaluate the model**: Use `model.evaluate()` with the testing data.\n",
    "- **Save the trained model**: Persist the trained model for future use."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}